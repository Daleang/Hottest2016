{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time, os, re, requests, got, cPickle as pickle, glob, random, string, subprocess, collections, difflib\n",
    "from tqdm import tqdm as progressbar\n",
    "from retry import retry\n",
    "from zipfile import ZipFile\n",
    "rand_str = lambda n: ''.join([random.choice(string.lowercase) for i in xrange(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@retry(tries=5, delay=5)\n",
    "def download_url(url, stream = False):\n",
    "    return requests.get(url, stream=stream, headers = {'User-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_closest_match(a,lst):\n",
    "    \"\"\"Check a against every item in lst, return\n",
    "    a tuple of the closest match, its index in the\n",
    "    list, and the quick_ratio\"\"\"\n",
    "    match_lst = [(l,i,difflib.SequenceMatcher(None,a,l).quick_ratio()) for i,l in enumerate(lst)]\n",
    "    sorted_match_lst = sorted(match_lst, key = lambda match: match[2], reverse = True)\n",
    "    return sorted_match_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def image2text(image_file):\n",
    "    tmpfile = os.path.join ('ram',rand_str(10) + '.png')\n",
    "    diamond_template = '''convert ORIGINAL_IMAGE -resize 400% -morphology close diamond ''' + tmpfile + ''' ; tesseract ''' + tmpfile + ''' stdout '''\n",
    "    ocr_result = subprocess.check_output(diamond_template.replace('ORIGINAL_IMAGE',image_file), shell=True)\n",
    "    os.remove(tmpfile)\n",
    "    return ocr_result\n",
    "\n",
    "def isolate_images(ocr_result, list_to_check, minimum_closeness=0.75):\n",
    "    ocr_cleanup = [x.strip() for x in ocr_result.split('\\n') if len(x) > 4 and len(re.findall(r'\\w\\w\\w',x)) > 0]\n",
    "    good_result = bool(re.findall(\"Your[^\\n]*vote.*\",ocr_result, re.IGNORECASE))\n",
    "    \n",
    "    if not good_result:\n",
    "        return False\n",
    "\n",
    "    # Find the line that says \"Your hottest 100 votes\" or \"Your votes\", because all the votes come after it\n",
    "    OCR_CLEANUP = [x.upper() for x in ocr_cleanup]\n",
    "    your_hottest_100_votes = get_closest_match('YOUR HOTTEST 100 VOTES', OCR_CLEANUP )\n",
    "    your_votes = get_closest_match('YOUR VOTES', OCR_CLEANUP )\n",
    "    if your_hottest_100_votes[2] > minimum_closeness:\n",
    "        your_votes_index = your_hottest_100_votes[1]\n",
    "    elif your_hottest_100_votes[2] < your_votes[2] and your_votes[2] > minimum_closeness:\n",
    "        your_votes_index = your_votes[1]\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    votes = ocr_cleanup[your_votes_index+1:]\n",
    "    real_votes = []\n",
    "\n",
    "    \"\"\" Iterate over the lines, checking them against the list\n",
    "    Also check if line + the next line is on the list.\n",
    "    Find the best matching line, if it meets the minimum_closeness,\n",
    "    add it to the list.\"\"\"\n",
    "    votes_iter = iter(enumerate(votes))\n",
    "    for i,vote in votes_iter:\n",
    "        better_votes = [{'vote':vote,'skippable':0}]\n",
    "        try:\n",
    "            better_votes.append({'vote':vote+votes[i+1],'skippable':1})\n",
    "            better_votes.append({'vote':vote+votes[i+1]+votes[i+2],'skippable':2})\n",
    "        except IndexError:\n",
    "            pass\n",
    "        for bv in better_votes:\n",
    "            match = get_closest_match(bv['vote'], list_to_check)\n",
    "            bv['best_candidate'] = match[0]\n",
    "            bv['best_score']     = match[2]\n",
    "        closest_vote_in_list = sorted(better_votes , key = lambda vote: vote['best_score'], reverse = True)[0]\n",
    "        if closest_vote_in_list['best_score'] > minimum_closeness:\n",
    "            real_votes.append(closest_vote_in_list['best_candidate'])\n",
    "            for x in range(closest_vote_in_list['skippable']):\n",
    "                votes_iter.next()\n",
    "\n",
    "    return real_votes    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def download_tweets(start,end,query):\n",
    "    tweetCriteria = got.manager.TweetCriteria()\n",
    "    tweetCriteria.since = start \n",
    "    tweetCriteria.until = end   \n",
    "    tweetCriteria.querySearch = query    \n",
    "\n",
    "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tweets_to_image_files(all_tweets, image_file_name_zip):\n",
    "\n",
    "    image_zip = ZipFile(image_file_name_zip,'w')\n",
    "    image_zip.close()\n",
    "    \n",
    "    for tweet in progressbar(all_tweets):\n",
    "        shortened_tweet = tweet.text.replace(' ','')\n",
    "        if 'instagram.com' in shortened_tweet:\n",
    "            site  = 'instagram.com'\n",
    "        elif 'twitter.com' in shortened_tweet:\n",
    "            site = 'twitter.com'\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        address_and_rest_of_line = 'https://' + re.findall(r' *([^ /]*'+site + r'.*)',tweet.text)[0]\n",
    "        address1 = address_and_rest_of_line.split()[0]\n",
    "        try:\n",
    "            address2 = address_and_rest_of_line.split()[0] + address_and_rest_of_line.split()[1]\n",
    "        except IndexError:\n",
    "            address2 = address1\n",
    "\n",
    "        html_page = download_url(address1)\n",
    "        if html_page.status_code == 404:\n",
    "            time.sleep(3)\n",
    "            html_page =  download_url(address2)\n",
    "            if html_page.status_code == 404:\n",
    "                print('404:' + tweet.text)\n",
    "                continue\n",
    "\n",
    "        #Check for redirection\n",
    "        if 'META http-equiv' in html_page.text:\n",
    "            html_page = download_url(re.findall(r'URL=([^\"]*)',html_page.text)[0])\n",
    "\n",
    "        @retry(tries=5, delay=5)\n",
    "        def get_image(html_page):\n",
    "            try:\n",
    "                image_location = re.findall(r'http[^>?\"]*',re.findall(r'og:image\" content[^>].*',html_page.text)[0])[0]\n",
    "            except IndexError:\n",
    "                return None, None\n",
    "            image_data = download_url(image_location, stream=True)\n",
    "            image_data.raw.decode_content = True\n",
    "            d = image_data.raw.read()\n",
    "            return d, image_location\n",
    "        d, imagelocation = get_image(html_page)\n",
    "        if d is None and imagelocation is None:\n",
    "            continue\n",
    "        \n",
    "        user = tweet.username\n",
    "        date = str(tweet.date).replace(\" \",\"_\").replace(\":\",'-')\n",
    "        fname = user + '~' + date\n",
    "        if '.jpg' in imagelocation:\n",
    "            fname = fname + '.jpg'\n",
    "        elif '.png' in imagelocation:\n",
    "            fname = fname + '.png'\n",
    "        else:\n",
    "            fname = fname + '.jpg'\n",
    "        #print fname\n",
    "        \n",
    "        image_zip = ZipFile(image_file_name_zip,'a')\n",
    "        image_zip.writestr(fname, d)\n",
    "        image_zip.close()\n",
    "\n",
    "        time.sleep(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tweets_to_image_files(unique_tweets,'2015.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multi_process_run(func, arglist, max_processes = 7, timeout = 10):\n",
    "    from tqdm import tqdm as progressbar\n",
    "    from multiprocessing import Pool\n",
    "    current_processes = 0\n",
    "    process_list = []\n",
    "    #outputs = []\n",
    "    results = []\n",
    "    for arg in progressbar(arglist):\n",
    "        if current_processes == max_processes:\n",
    "            process_and_output = process_list.pop(0)\n",
    "            results.append(process_and_output[1].get(timeout=timeout))\n",
    "            process_and_output[0].close()\n",
    "            current_processes = current_processes - 1\n",
    "            \n",
    "        p = Pool (processes = 1)\n",
    "        output = p.apply_async(func,arg)\n",
    "        process_list.append((p,output,arg))\n",
    "        current_processes = current_processes + 1\n",
    "    # Get any processes still running\n",
    "    for process in process_list:\n",
    "        results.append(process[1].get(timeout=timeout))\n",
    "        process[0].close()\n",
    "\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def zip_to_texts(zip_filename, processes=7, timeout=600):\n",
    "    zf = ZipFile(zip_filename)\n",
    "    \n",
    "    tmpdir = os.path.join('ram','tmp'+rand_str(10))\n",
    "    os.mkdir (tmpdir)\n",
    "    zf.extractall(tmpdir)\n",
    "    filenames = glob.glob(os.path.join(tmpdir,'*'))\n",
    "    #arguments = [(filename, compare_list) for filename in filenames]\n",
    "    \n",
    "    results = multi_process_run_fast(image2text,filenames,processes,timeout)\n",
    "    \n",
    "    for filename in filenames:\n",
    "        os.remove(filename)\n",
    "    os.rmdir(tmpdir)\n",
    "    \n",
    "    simple_filenames = [os.path.split(filename)[-1] for filename in filenames]\n",
    "    \n",
    "    return zip (simple_filenames, results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_process_run_fast(func, arglist, max_processes = 14, timeout = 30):\n",
    "    from tqdm import tqdm as progressbar\n",
    "    from multiprocessing import Pool\n",
    "    current_processes = 0\n",
    "    process_list = []\n",
    "    results = []\n",
    "    for i,arg in progressbar(enumerate(arglist)):\n",
    "        if current_processes == max_processes:\n",
    "            while True not in [p[1].ready() for p in process_list]:\n",
    "                time.sleep(0.1)\n",
    "            finished_process = [p[1].ready() for p in process_list].index(True)\n",
    "            process_and_output = process_list.pop(finished_process)\n",
    "            results[process_and_output[3]] = process_and_output[1].get(timeout=timeout)\n",
    "            process_and_output[0].close()\n",
    "            current_processes = current_processes - 1\n",
    "            \n",
    "        p = Pool (processes = 1)\n",
    "        output = p.apply_async(func,(arg,))\n",
    "        results.append(None)\n",
    "        process_list.append((p,output,arg,i))\n",
    "        current_processes = current_processes + 1\n",
    "    # Get any processes still running\n",
    "    for process in process_list:\n",
    "        results[process[3]] = process[1].get(timeout=timeout)\n",
    "        process[0].close()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
